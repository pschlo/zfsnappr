from __future__ import annotations
from typing import Optional, cast
from collections.abc import Collection
import logging
from itertools import pairwise

from ..zfs import Snapshot, ZfsCli, ZfsProperty, Dataset
from .send_receive_snap import send_receive_incremental, send_receive_initial
from zfsnappr.common.exception import ReplicationError


log = logging.getLogger(__name__)


def holdtag_src(dest_dataset: Dataset):
  return f'zfsnappr-sendbase-{dest_dataset.guid}'

def holdtag_dest(src_dataset: Dataset):
  return f'zfsnappr-recvbase-{src_dataset.guid}'


# TODO: raw send for encrypted datasets?
def replicate_snaps(
  source_cli: ZfsCli,
  source_snaps: Collection[Snapshot],
  dest_cli: ZfsCli,
  dest_dataset: str,
  initialize: bool,
  rollback: bool
):
  """
  replicates source_snaps to dest_dataset
  all source_snaps must be of same dataset

  Let S and D be the snapshots on source and dest, newest first.
  Then D[0] = S[b] for some index b.
  We call b the base index. It is used as an incremental basis for sending snapshots S[:b]
  """
  if not source_snaps:
    log.info(f'No source snapshots given, nothing to do')
    return

  source_dataset = next(iter(source_snaps)).dataset

  # sorting is required
  source_snaps = sorted(source_snaps, key=lambda s: s.timestamp, reverse=True)


  ##### PHASE 1: Critical preparation, check for abort conditions

  # ensure dest dataset exists
  dest_exists: bool = any(dest_dataset == d.name for d in dest_cli.get_all_datasets())
  if not dest_exists:
    if initialize:
      log.info(f"Creating destination dataset '{dest_dataset}' by transferring the oldest snapshot")
      source_dataset_type = source_cli.get_dataset(source_dataset).type
      send_receive_initial(
        clis=(source_cli, dest_cli),
        dest_dataset=dest_dataset,
        source_dataset_type=source_dataset_type,
        snapshot=source_snaps[-1],
        holdtags=(holdtag_src, holdtag_dest)
      )
    else:
      raise ReplicationError(f"Destination dataset '{dest_dataset}' does not exist and will not be created")

  # get dest snaps
  dest_snaps = dest_cli.get_all_snapshots(dest_dataset, sort_by=ZfsProperty.CREATION, reverse=True)
  
  # resolve hold tags
  source_tag = holdtag_src(dest_cli.get_dataset(dest_dataset))
  dest_tag = holdtag_dest(source_cli.get_dataset(source_dataset))

  # Determine latest common snapshot
  latest_common_snap = determine_latest_common((source_snaps, dest_snaps))

  # Update holds
  ensure_holds(
    (source_cli, dest_cli),
    (source_snaps, dest_snaps),
    (source_tag, dest_tag),
    datasets=(source_dataset, dest_dataset),
    latest_common_snap=latest_common_snap
  )

  if not dest_snaps:
    raise ReplicationError(f"Destination '{dest_dataset}' does not contain any snapshots")

  # figure out base index
  if latest_common_snap is None:
    raise ReplicationError(f"Source '{source_dataset}' and destination '{dest_dataset}' have no common snapshot")
  if latest_common_snap[1].guid != dest_snaps[0].guid:
    raise ReplicationError(f"Destination '{dest_dataset}' has snapshots newer than latest common snapshot '{latest_common_snap[1].shortname}'")
  base_index = next(i for i, s in enumerate(source_snaps) if s.guid == latest_common_snap[0].guid)

  # Determine sequence of source snapshots to transfer.
  # Default: transfer all source snapshots from common base to latest.
  transfer_sequence = list(reversed(source_snaps[:base_index+1]))

  assert transfer_sequence  # must at least contain a base snapshot
  if len(transfer_sequence) <= 1:
    log.info(f"Source '{source_dataset}' has no new snapshots to transfer")
    return

  # Find snapshot that cannot be transferred because their timestamp equals their predecessor
  for i, (a, b) in enumerate(pairwise(transfer_sequence)):
    if a.timestamp == b.timestamp:
      # Snapshot B cannot be sent
      raise ReplicationError(
        f"Cannot transfer snapshots from '{source_dataset}' to '{dest_dataset}': "
        f"snapshot '{b.shortname}' shares timestamp with predecessor '{a.shortname}'"
      )


  ##### PHASE 2: Everything technically good to go, do some quality-of-life checks before actual transfer

  assert len(transfer_sequence) >= 2
  
  # Optionally ensure dest is at snapshot
  if rollback:
    log.info(f"Rolling back destination '{dest_dataset}' to latest snapshot")
    dest_cli.rollback(dest_snaps[0].longname)


  ##### PHASE 3: Transfer snapshots sequentially

  total = len(transfer_sequence) - 1
  log.info(f"Transferring {total} snapshots from '{source_dataset}' to '{dest_dataset}'")
  for i, (_base, _snap) in enumerate(pairwise(transfer_sequence)):
    send_receive_incremental(
      clis=(source_cli, dest_cli),
      dest_dataset=dest_dataset,
      holdtags=(source_tag, dest_tag),
      snapshot=_snap,
      base=_base,
      unsafe_release=True  # base is guaranteed to be held
    )
    log.info(f'{i+1}/{total} transferred')
  dest_snaps = [s.with_dataset(dest_dataset) for s in reversed(transfer_sequence[1:])] + dest_snaps
  log.info(f'Transfer complete')


def ensure_holds(clis: tuple[ZfsCli,ZfsCli], snaps: tuple[list[Snapshot],list[Snapshot]], holdtags: tuple[str,str], latest_common_snap: tuple[Snapshot, Snapshot] | None, datasets: tuple[str, str]):
  """Ensures the latest common snapshot is held on both sides. Removes all other peer holdtags.

  After completion, one of these is true:
  1. There are no holdtags on either side, since there was no common snapshot
  2. There is exactly one holdtag on each side, on the latest common snapshot
  """
  # Get holds
  holds = (
    {s.longname: set[str]() for s in snaps[0]},
    {s.longname: set[str]() for s in snaps[1]}
  )
  for h in clis[0].get_holds([s.longname for s in snaps[0]]):
    holds[0][h.snap_longname].add(h.tag)
  for h in clis[1].get_holds([s.longname for s in snaps[1]]):
    holds[1][h.snap_longname].add(h.tag)

  if latest_common_snap is None:
    # Remove all peer holdtags
    release_snaps = (
      [s.longname for s in snaps[0]],
      [s.longname for s in snaps[1]]
    )
    _release_holds(clis, release_snaps, holdtags, current_holdtags=holds, datasets=datasets)
    return

  # Ensure latest common snap is held
  src_snap, dest_snap = latest_common_snap
  if holdtags[0] not in holds[0][src_snap.longname]:
    log.info(f"Creating hold for latest common snapshot '{src_snap.shortname}' on source '{src_snap.dataset}'")
    clis[0].hold([src_snap.longname], tag=holdtags[0])
  if holdtags[1] not in holds[1][dest_snap.longname]:
    log.info(f"Creating hold for latest common snapshot '{dest_snap.shortname}' on destination '{dest_snap.dataset}'")
    clis[1].hold([dest_snap.longname], tag=holdtags[1])

  # Remove all other holdtags
  release_snaps = (
    [s.longname for s in snaps[0] if s.guid != latest_common_snap[0].guid],
    [s.longname for s in snaps[1] if s.guid != latest_common_snap[1].guid]
  )
  _release_holds(clis, release_snaps, holdtags, current_holdtags=holds, datasets=datasets)


def determine_latest_common(snaps: tuple[list[Snapshot],list[Snapshot]]) -> tuple[Snapshot, Snapshot] | None:
  """Finds the latest snapshot that exists on both sides."""
  guid_to_snap = (
    {s.guid: s for s in snaps[0]},
    {s.guid: s for s in snaps[1]}
  )
  common_guids = guid_to_snap[0].keys() & guid_to_snap[1].keys()
  if not common_guids:
    return None

  # For determinism, sort by GUID if timestamps are equal.
  # Just to be safe, ensure the snapshot is actually the latest common snapshot on both sides.
  _latest_guid_src = max(common_guids, key=lambda g: (guid_to_snap[0][g].timestamp, g))
  _latest_guid_dest = max(common_guids, key=lambda g: (guid_to_snap[1][g].timestamp, g))
  assert _latest_guid_src == _latest_guid_dest
  latest_guid = _latest_guid_src
  latest_common_snap = (guid_to_snap[0][latest_guid], guid_to_snap[1][latest_guid])
  log.debug(f"Latest common snapshot is '{latest_common_snap[0].longname}' on source, '{latest_common_snap[1].longname}' on destination")

  return latest_common_snap


def _release_holds(clis: tuple[ZfsCli, ZfsCli], snaps: tuple[list[str], list[str]], release_holdtags: tuple[str, str], current_holdtags: tuple[dict[str, set[str]], dict[str, set[str]]], datasets: tuple[str, str]):
  # Filter for snaps that have the holdtags
  release_snaps = (
    [s for s in snaps[0] if release_holdtags[0] in current_holdtags[0][s]],
    [s for s in snaps[1] if release_holdtags[1] in current_holdtags[1][s]],
  )
  if release_snaps[0]:
    log.info(f"Releasing {len(release_snaps[0])} obsolete holds in source '{datasets[0]}'")
  if release_snaps[1]:
    log.info(f"Releasing {len(release_snaps[1])} obsolete holds in destination '{datasets[1]}'")
  clis[0].release_hold(release_snaps[0], release_holdtags[0])
  clis[1].release_hold(release_snaps[1], release_holdtags[1])
